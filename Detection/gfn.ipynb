{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d059f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# import tqdm as notebook_tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7023d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Preprocessing of data\n",
    "# 1. Text to lowercase\n",
    "# 2. Remove accents\n",
    "#\n",
    "# Ένας υπέροχος ποιητής -> ενας υπεροχος ποιητης\n",
    "\n",
    "\n",
    "# %%\n",
    "def strip_accents_and_lowercase(s):\n",
    "    if type(s) == str:\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                       if unicodedata.category(c) != 'Mn').lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52518f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "transformers.logging.set_verbosity_error(\n",
    ")  #δεν εχει λειτουργία κανει supress καποια warnings\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer_greek = AutoTokenizer.from_pretrained(\n",
    "    'nlpaueb/bert-base-greek-uncased-v1')\n",
    "lm_model_greek = AutoModel.from_pretrained(\n",
    "    'nlpaueb/bert-base-greek-uncased-v1', return_dict=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc66ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df: pd.DataFrame = pd.read_csv('../Dataset/greek.csv', delimiter=';')\n",
    "df = df.dropna()  # removes None values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f7a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Check that there are no nan values\n",
    "assert df.isnull().values.any() == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab5c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "titles = df['title'].apply(strip_accents_and_lowercase)\n",
    "labels = df['is_fake']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc560434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.547019\n",
       "1    0.452981\n",
       "Name: is_fake, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# check labels distribution\n",
    "labels.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0601ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "train_title, test_title, train_labels, test_labels = train_test_split(  #to Text ennoei ton titlo etsi?\n",
    "    titles, labels, random_state=2022, test_size=0.3, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56c8eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Tokenizaion\n",
    "# Get the length of all the titles in the train set\n",
    "seq_len = [len(i.split()) for i in train_title]  # μέγεθος τίτλου σε λέξεις\n",
    "\n",
    "pd.Series(seq_len).hist(bins=30)  # δημιουργία ιστογράμματος των μεγεθών\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71bb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# define max sequence lenght (why?)\n",
    "max_seq_len = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555e0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# tokenization and encoding of the sequences in the training and testing set\n",
    "# truncation=True, -> limits token's len to max_seq_len\n",
    "# for smaller tokens, pad with 0 until max_seq_len\n",
    "tokens_train = tokenizer_greek.batch_encode_plus(train_title.tolist(),\n",
    "                                                 max_length=max_seq_len,\n",
    "                                                 padding='max_length',\n",
    "                                                 truncation=True,\n",
    "                                                 return_token_type_ids=False)\n",
    "\n",
    "tokens_test = tokenizer_greek.batch_encode_plus(test_title.tolist(),\n",
    "                                                max_length=max_seq_len,\n",
    "                                                padding='max_length',\n",
    "                                                truncation=True,\n",
    "                                                return_token_type_ids=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f49c2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Convert Integer Sequences to Tensors\n",
    "\n",
    "# For train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())  \n",
    "\n",
    "# For test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c5728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "batch_size = 64\n",
    "epochs = 5 \n",
    "\n",
    "# wrap tensors\n",
    "# the TensorDataset is a ready to use class to represent our data as a list of tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y) \n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e25d45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define the Model Custom Architecture\n",
    "class BERT_Fake(nn.Module):\n",
    "\n",
    "    def __init__(self, bert) -> None:\n",
    "        super(BERT_Fake, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "        # DropoutLayer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "        # Dense Layer 1\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, send_id, mask):\n",
    "        # pass inputs to model\n",
    "        _, cls_hs = self.bert(send_id, attention_mask=mask)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b141f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Pass the pre-trained BERT to our custom architecture\n",
    "model = BERT_Fake(lm_model_greek)\n",
    "\n",
    "# Push model to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ace0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b55959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Compute the Class Weights\n",
    "# With class weighting enabled, the sum is replaced by a weighted sum instead so that each sample contributes to the loss proportionally to the sample's class weight\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                     classes=np.unique(train_labels),\n",
    "                                     y=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9ec8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Convert weights to tensors\n",
    "weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "weigths = weights.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss(weight=weights)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "525d6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# writer = SummaryWriter('runs/greek-fake-news')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4568bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def train():\n",
    "\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    total_preds = []\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Update after every Number of batches\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step,\n",
    "                                                       len(train_dataloader)))\n",
    "\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(sent_id, mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        # Make the grads zero\n",
    "        model.zero_grad()\n",
    "        # Do the backward step of the loss calculation through chain derivatives\n",
    "        total_loss = total_loss + loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        # TO TEST IT\n",
    "        #torch.nn.utils.clip_grap_norm_(model.paremeters(),1.0)\n",
    "        # Do the optimizer step and update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Model predictions are stored on GPU. Push it to CPU\n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "\n",
    "        # Append the model predictions\n",
    "        total_preds.append(outputs)\n",
    "\n",
    "    # Compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # The predictions are in the form of (no. of batches, size of batch, no. of classes)\n",
    "    # Reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # Return the loss and predictions\n",
    "    return avg_loss, total_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "187701ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n",
      "Training Loss: 0.745\n",
      "Epoch 2 / 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs))\n\u001b[1;32m---> 10\u001b[0m     train_loss, preds \u001b[39m=\u001b[39m train()\n\u001b[0;32m     12\u001b[0m     \u001b[39m# To find out what happends with the accuracy per epoch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m# writer.add_scalar('Training Loss', train_loss, epoch)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[21], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     36\u001b[0m \u001b[39m# Model predictions are stored on GPU. Push it to CPU\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     39\u001b[0m \u001b[39m# Append the model predictions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m total_preds\u001b[39m.\u001b[39mappend(outputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# model training\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    train_loss, preds = train()\n",
    "\n",
    "    # To find out what happends with the accuracy per epoch\n",
    "    # writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'Training Loss: {train_loss:.3f}')\n",
    "torch.save(model.state_dict(), 'saved_weights.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# writer.close()\n",
    "\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Get Predictions for the Test Data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f6a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def conf_to_metrics(conf):\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = tp / (tp + fp)\n",
    "    fscore = 2 * sensitivity * precision / (sensitivity + precision)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"fscore\": fscore,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93255fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "preds = np.argmax(preds, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dfd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "conf = confusion_matrix(test_y, preds, labels=[0, 1])\n",
    "conf_to_metrics(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Plot ROC curve\n",
    "auc_score = roc_auc_score(test_y, preds)\n",
    "fpr, tpr, thresholds = roc_curve(test_y, preds, pos_label=1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, 'b', label='AUC = %.2f' % auc_score)\n",
    "ax.plot([0, 1], [0, 1], 'r--')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_ylabel('Sensitivity')\n",
    "ax.set_xlabel('1 - Specificity')\n",
    "ax.legend(loc='lower right')\n",
    "nm = 'roc_curve' + str(round(auc_score, 3)) + '.svg'\n",
    "fig.savefig(nm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "print(classification_report(test_y, preds, target_names=['Fake', 'Real']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
